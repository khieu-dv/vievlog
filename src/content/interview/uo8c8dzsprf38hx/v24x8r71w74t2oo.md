---
title: "Distributed Systems (Phần 3) - Backend Interview Questions"
postId: "v24x8r71w74t2oo"
category: "BackEnd Interview"
created: "2/9/2025"
updated: "2/9/2025"
---

# Distributed Systems (Phần 3) - Backend Interview Questions


## 63. Fallacies của Distributed Computing?

**Trả lời:** Fallacies of Distributed Computing là 8 assumptions sai lầm mà developers thường có khi thiết kế distributed systems. Những assumption này dẫn đến system failures và performance issues.

### 8 Fallacies và Implications:

#### 1. "The network is reliable"
```python
# Wrong assumption: Network calls always succeed
def get_user_data(user_id):
    response = requests.get(f"http://user-service/users/{user_id}")
    return response.json()  # What if network fails?

# Reality: Networks fail frequently
class ResilientUserClient:
    def __init__(self, base_url, max_retries=3):
        self.base_url = base_url
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # Configure connection pooling and timeouts
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,
            pool_maxsize=20,
            max_retries=urllib3.util.Retry(
                total=max_retries,
                backoff_factor=0.3,
                status_forcelist=[500, 502, 503, 504]
            )
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
    
    def get_user_data(self, user_id):
        try:
            response = self.session.get(
                f"{self.base_url}/users/{user_id}",
                timeout=(5, 30)  # Connect timeout, read timeout
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            # Handle network failures gracefully
            logging.error(f"Failed to fetch user {user_id}: {e}")
            
            # Return cached data if available
            cached_data = self.get_cached_user(user_id)
            if cached_data:
                return cached_data
            
            # Or return default/placeholder data
            return {
                'id': user_id,
                'name': 'Unknown User',
                'status': 'unavailable'
            }
    
    def get_cached_user(self, user_id):
        # Check local cache, Redis, etc.
        return cache.get(f"user:{user_id}")
```

#### 2. "Latency is zero"
```java
// Wrong: Treating remote calls like local calls
public class OrderService {
    private UserService userService;
    private InventoryService inventoryService;
    private PaymentService paymentService;
    
    // This looks simple but has hidden latency costs
    public Order createOrder(OrderRequest request) {
        User user = userService.getUser(request.getUserId());           // 50ms
        boolean available = inventoryService.checkStock(request.getItems()); // 75ms
        PaymentResult payment = paymentService.charge(request.getPayment()); // 100ms
        
        // Total: 225ms+ just for remote calls!
        return new Order(user, request.getItems(), payment);
    }
}

// Better: Parallel execution and caching
@Service
public class OptimizedOrderService {
    
    @Autowired private UserService userService;
    @Autowired private InventoryService inventoryService; 
    @Autowired private PaymentService paymentService;
    
    @Cacheable("users")
    public CompletableFuture<User> getUserAsync(String userId) {
        return CompletableFuture.supplyAsync(() -> userService.getUser(userId));
    }
    
    public CompletableFuture<Order> createOrderAsync(OrderRequest request) {
        // Execute calls in parallel
        CompletableFuture<User> userFuture = getUserAsync(request.getUserId());
        CompletableFuture<Boolean> stockFuture = CompletableFuture
            .supplyAsync(() -> inventoryService.checkStock(request.getItems()));
        
        return CompletableFuture.allOf(userFuture, stockFuture)
            .thenCompose(v -> {
                User user = userFuture.join();
                Boolean stockAvailable = stockFuture.join();
                
                if (!stockAvailable) {
                    throw new InsufficientStockException("Items not available");
                }
                
                // Only charge payment after validating user and stock
                return CompletableFuture
                    .supplyAsync(() -> paymentService.charge(request.getPayment()))
                    .thenApply(payment -> new Order(user, request.getItems(), payment));
            });
    }
    
    // Batch operations to reduce round trips
    public List<User> getMultipleUsers(List<String> userIds) {
        // Single call instead of N calls
        return userService.getUsersByIds(userIds);
    }
}
```

#### 3. "Bandwidth is infinite"
```javascript
// Wrong: Sending large payloads without consideration
class UserService {
    async getUserProfile(userId) {
        // Sending massive object with all data
        const response = await fetch(`/api/users/${userId}/complete-profile`);
        return response.json(); // Could be MBs of data
    }
}

// Better: Selective loading and compression
class OptimizedUserService {
    async getUserProfile(userId, fields = ['basic']) {
        // Request only needed fields
        const queryParams = new URLSearchParams({
            fields: fields.join(','),
            compress: 'true'
        });
        
        const response = await fetch(
            `/api/users/${userId}?${queryParams}`,
            {
                headers: {
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Accept': 'application/json'
                }
            }
        );
        
        return response.json();
    }
    
    // Pagination for large datasets
    async getUserPosts(userId, page = 1, limit = 20) {
        const response = await fetch(
            `/api/users/${userId}/posts?page=${page}&limit=${limit}`
        );
        return response.json();
    }
    
    // Streaming for real-time data
    async streamUserActivity(userId, callback) {
        const eventSource = new EventSource(`/api/users/${userId}/activity-stream`);
        
        eventSource.onmessage = (event) => {
            const activity = JSON.parse(event.data);
            callback(activity);
        };
        
        return eventSource;
    }
}

// Server-side: Implement GraphQL for efficient data fetching
const typeDefs = `
    type User {
        id: ID!
        name: String!
        email: String!
        profile: UserProfile
        posts: [Post!]!
        activities: [Activity!]!
    }
    
    type Query {
        user(id: ID!, fields: [String!]): User
    }
`;

const resolvers = {
    User: {
        profile: (parent, args, context) => {
            // Only load if requested
            if (context.requestedFields.includes('profile')) {
                return context.dataloaders.profile.load(parent.id);
            }
            return null;
        },
        
        posts: (parent, args, context) => {
            if (context.requestedFields.includes('posts')) {
                return context.dataloaders.posts.load(parent.id);
            }
            return [];
        }
    }
};
```

#### 4. "The network is secure"
```go
// Wrong: Trusting network communication
func getUserData(userID string) (*User, error) {
    // Unencrypted HTTP request
    resp, err := http.Get("http://internal-service/users/" + userID)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var user User
    json.NewDecoder(resp.Body).Decode(&user)
    return &user, nil
}

// Better: Secure communication with authentication
type SecureClient struct {
    httpClient   *http.Client
    apiKey       string
    baseURL      string
    certificates *tls.Config
}

func NewSecureClient(baseURL, apiKey string) *SecureClient {
    // Configure TLS
    tlsConfig := &tls.Config{
        MinVersion: tls.VersionTLS12,
        CurvePreferences: []tls.CurveID{
            tls.CurveP521,
            tls.CurveP384,
            tls.CurveP256,
        },
        PreferServerCipherSuites: true,
        CipherSuites: []uint16{
            tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
            tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,
            tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
        },
    }
    
    transport := &http.Transport{
        TLSClientConfig: tlsConfig,
        IdleConnTimeout: 30 * time.Second,
    }
    
    return &SecureClient{
        httpClient: &http.Client{
            Transport: transport,
            Timeout:   30 * time.Second,
        },
        apiKey:  apiKey,
        baseURL: baseURL,
    }
}

func (c *SecureClient) GetUserData(userID string) (*User, error) {
    req, err := http.NewRequest("GET", c.baseURL+"/users/"+userID, nil)
    if err != nil {
        return nil, err
    }
    
    // Add authentication
    req.Header.Set("Authorization", "Bearer "+c.apiKey)
    req.Header.Set("X-Request-ID", generateRequestID())
    req.Header.Set("User-Agent", "SecureClient/1.0")
    
    // Add request signing for integrity
    signature := c.signRequest(req)
    req.Header.Set("X-Signature", signature)
    
    resp, err := c.httpClient.Do(req)
    if err != nil {
        return nil, fmt.Errorf("request failed: %w", err)
    }
    defer resp.Body.Close()
    
    // Verify response integrity
    if !c.verifyResponse(resp) {
        return nil, errors.New("response integrity check failed")
    }
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("unexpected status: %d", resp.StatusCode)
    }
    
    var user User
    if err := json.NewDecoder(resp.Body).Decode(&user); err != nil {
        return nil, fmt.Errorf("decode failed: %w", err)
    }
    
    return &user, nil
}

func (c *SecureClient) signRequest(req *http.Request) string {
    // Implement HMAC signing for request integrity
    mac := hmac.New(sha256.New, []byte(c.apiKey))
    mac.Write([]byte(req.Method))
    mac.Write([]byte(req.URL.Path))
    mac.Write([]byte(req.Header.Get("X-Request-ID")))
    return hex.EncodeToString(mac.Sum(nil))
}
```

#### 5. "Topology doesn't change"
```python
# Wrong: Hard-coded service locations
class PaymentClient:
    def __init__(self):
        # Hard-coded endpoints - what if they change?
        self.primary_endpoint = "http://payment-service-1:8080"
        self.backup_endpoint = "http://payment-service-2:8080"
    
    def process_payment(self, payment_data):
        try:
            return self._call_endpoint(self.primary_endpoint, payment_data)
        except Exception:
            return self._call_endpoint(self.backup_endpoint, payment_data)

# Better: Service discovery and dynamic configuration
import consul
from typing import List, Optional

class DynamicPaymentClient:
    def __init__(self, consul_host='localhost', consul_port=8500):
        self.consul = consul.Consul(host=consul_host, port=consul_port)
        self.service_cache = {}
        self.cache_ttl = 30  # seconds
        self.last_discovery = {}
    
    def discover_services(self, service_name: str) -> List[dict]:
        """Discover healthy service instances"""
        now = time.time()
        
        # Check cache first
        if (service_name in self.service_cache and 
            now - self.last_discovery.get(service_name, 0) < self.cache_ttl):
            return self.service_cache[service_name]
        
        try:
            # Discover services from Consul
            _, services = self.consul.health.service(
                service_name, 
                passing=True  # Only healthy instances
            )
            
            instances = []
            for service in services:
                instance = {
                    'host': service['Service']['Address'] or service['Node']['Address'],
                    'port': service['Service']['Port'],
                    'id': service['Service']['ID'],
                    'tags': service['Service']['Tags']
                }
                instances.append(instance)
            
            # Update cache
            self.service_cache[service_name] = instances
            self.last_discovery[service_name] = now
            
            return instances
            
        except Exception as e:
            logging.error(f"Service discovery failed for {service_name}: {e}")
            # Return cached data if available
            return self.service_cache.get(service_name, [])
    
    def get_service_endpoint(self, service_name: str) -> Optional[str]:
        """Get a service endpoint using load balancing"""
        instances = self.discover_services(service_name)
        
        if not instances:
            return None
        
        # Simple round-robin load balancing
        if not hasattr(self, '_lb_counter'):
            self._lb_counter = {}
        
        counter = self._lb_counter.get(service_name, 0)
        instance = instances[counter % len(instances)]
        self._lb_counter[service_name] = counter + 1
        
        return f"http://{instance['host']}:{instance['port']}"
    
    def process_payment(self, payment_data):
        """Process payment with dynamic service discovery"""
        max_attempts = 3
        
        for attempt in range(max_attempts):
            endpoint = self.get_service_endpoint('payment-service')
            
            if not endpoint:
                raise ServiceUnavailableError("No payment service instances available")
            
            try:
                return self._call_endpoint(endpoint, payment_data)
                
            except Exception as e:
                logging.warning(f"Payment attempt {attempt + 1} failed on {endpoint}: {e}")
                
                if attempt == max_attempts - 1:
                    raise PaymentError("All payment service attempts failed")
                
                # Remove failed instance from cache temporarily
                self._mark_instance_unhealthy(endpoint)
        
    def _mark_instance_unhealthy(self, endpoint: str):
        """Remove unhealthy instance from cache"""
        for service_name, instances in self.service_cache.items():
            self.service_cache[service_name] = [
                inst for inst in instances 
                if f"http://{inst['host']}:{inst['port']}" != endpoint
            ]
```

#### 6. "There is one administrator"
```yaml
# Wrong: Single point of administration
# docker-compose.yml - single admin managing everything
version: '3.8'
services:
  app:
    image: myapp:latest
    environment:
      - DB_PASSWORD=hardcoded_password
      - API_KEY=hardcoded_key
    ports:
      - "8080:8080"

# Better: Distributed administration with proper secrets management
# Using Kubernetes with RBAC and secrets
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production
type: Opaque
data:
  db-password: <base64-encoded-password>
  api-key: <base64-encoded-key>

\---
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
data:
  app.properties: |
    database.host=postgres-service
    database.port=5432
    cache.enabled=true
    logging.level=INFO

\---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      serviceAccountName: app-service-account
      containers:
      - name: app
        image: myapp:latest
        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: db-password
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: api-key
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: config-volume
        configMap:
          name: app-config

\---
# RBAC for team-based administration
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: production
  name: app-admin
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

\---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-admin-binding
  namespace: production
subjects:
- kind: User
  name: dev-team
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: app-admin
  apiGroup: rbac.authorization.k8s.io
```

#### 7. "Transport cost is zero"
```rust
// Wrong: Ignoring serialization/deserialization costs
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Debug)]
struct UserProfile {
    id: u64,
    name: String,
    email: String,
    // Huge nested objects
    preferences: UserPreferences,
    activity_history: Vec<Activity>, // Could be thousands of items
    social_connections: Vec<Connection>,
    metadata: serde_json::Value, // Arbitrary JSON
}

// This is expensive to serialize/deserialize and transfer
fn get_user_profile(user_id: u64) -> Result<UserProfile, Box<dyn std::error::Error>> {
    let profile = fetch_from_database(user_id)?;
    
    // Expensive: serializing large object
    let json = serde_json::to_string(&profile)?;
    
    // Expensive: sending large payload over network
    let response = send_to_client(&json)?;
    
    Ok(profile)
}

// Better: Efficient data transfer with compression and selective loading
use flate2::write::GzEncoder;
use flate2::Compression;
use std::io::Write;

#[derive(Serialize, Deserialize, Debug)]
struct BasicUserProfile {
    id: u64,
    name: String,
    email: String,
}

#[derive(Serialize, Deserialize, Debug)]
struct ExtendedUserProfile {
    basic: BasicUserProfile,
    preferences: Option<UserPreferences>,
    recent_activity: Option<Vec<Activity>>, // Limited to recent items
}

impl UserService {
    // Lightweight method for basic info
    fn get_basic_profile(&self, user_id: u64) -> Result<BasicUserProfile, ServiceError> {
        // Only fetch essential fields
        let profile = self.db.query(
            "SELECT id, name, email FROM users WHERE id = ?",
            &[&user_id]
        )?;
        
        Ok(profile)
    }
    
    // Method with selective loading
    fn get_extended_profile(
        &self, 
        user_id: u64, 
        include_preferences: bool,
        include_activity: bool,
        activity_limit: Option<usize>
    ) -> Result<ExtendedUserProfile, ServiceError> {
        
        let basic = self.get_basic_profile(user_id)?;
        
        let preferences = if include_preferences {
            Some(self.get_user_preferences(user_id)?)
        } else {
            None
        };
        
        let recent_activity = if include_activity {
            let limit = activity_limit.unwrap_or(10);
            Some(self.get_recent_activity(user_id, limit)?)
        } else {
            None
        };
        
        Ok(ExtendedUserProfile {
            basic,
            preferences,
            recent_activity,
        })
    }
    
    // Compressed data transfer
    fn serialize_compressed<T: Serialize>(&self, data: &T) -> Result<Vec<u8>, ServiceError> {
        let json = serde_json::to_string(data)?;
        
        let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
        encoder.write_all(json.as_bytes())?;
        let compressed = encoder.finish()?;
        
        // Log compression ratio for monitoring
        let original_size = json.len();
        let compressed_size = compressed.len();
        let ratio = (compressed_size as f64 / original_size as f64) * 100.0;
        
        log::info!(
            "Compression: {} bytes -> {} bytes ({:.1}%)", 
            original_size, compressed_size, ratio
        );
        
        Ok(compressed)
    }
    
    // Binary protocol for high-performance scenarios
    fn serialize_binary<T: Serialize>(&self, data: &T) -> Result<Vec<u8>, ServiceError> {
        // Using MessagePack for smaller payloads
        let packed = rmp_serde::to_vec(data)?;
        Ok(packed)
    }
}

// Protocol Buffers for even better performance
// user.proto
/*
syntax = "proto3";

message UserProfile {
    uint64 id = 1;
    string name = 2;
    string email = 3;
    
    optional UserPreferences preferences = 4;
    repeated Activity recent_activity = 5;
}

message UserPreferences {
    string theme = 1;
    bool notifications_enabled = 2;
    string language = 3;
}

message Activity {
    uint64 timestamp = 1;
    string action = 2;
    string resource = 3;
}
*/
```

#### 8. "The network is homogeneous"
```python
# Wrong: Assuming all network segments are the same
class VideoStreamingService:
    def stream_video(self, video_id, user_id):
        # Same high-quality stream for all users
        video_url = f"https://cdn.example.com/videos/{video_id}/4k.mp4"
        return {"stream_url": video_url}

# Better: Adaptive streaming based on network conditions
import geoip2.database
from user_agents import parse

class AdaptiveStreamingService:
    def __init__(self):
        self.geoip_reader = geoip2.database.Reader('GeoLite2-City.mmdb')
        self.quality_profiles = {
            'mobile_2g': {'bitrate': 200, 'resolution': '240p'},
            'mobile_3g': {'bitrate': 500, 'resolution': '360p'},
            'mobile_4g': {'bitrate': 1200, 'resolution': '720p'},
            'wifi': {'bitrate': 2500, 'resolution': '1080p'},
            'fiber': {'bitrate': 8000, 'resolution': '4k'}
        }
    
    def stream_video(self, video_id, user_id, request_info):
        # Detect user's network conditions
        network_profile = self.detect_network_profile(request_info)
        
        # Select appropriate quality
        quality = self.select_quality(network_profile)
        
        # Choose optimal CDN endpoint
        cdn_endpoint = self.select_cdn_endpoint(request_info['client_ip'])
        
        # Generate adaptive streaming manifest
        manifest = self.generate_manifest(video_id, quality, cdn_endpoint)
        
        return {
            'manifest_url': manifest,
            'quality_profile': quality,
            'cdn_endpoint': cdn_endpoint,
            'adaptive_streaming': True
        }
    
    def detect_network_profile(self, request_info):
        user_agent = parse(request_info.get('user_agent', ''))
        client_ip = request_info.get('client_ip')
        connection_speed = request_info.get('connection_speed')  # From client-side test
        
        # Mobile device detection
        if user_agent.is_mobile:
            if connection_speed and connection_speed < 1000:  # < 1Mbps
                return 'mobile_2g'
            elif connection_speed and connection_speed < 3000:  # < 3Mbps
                return 'mobile_3g'
            else:
                return 'mobile_4g'
        
        # Geographic considerations
        try:
            response = self.geoip_reader.city(client_ip)
            country = response.country.iso_code
            
            # Countries with typically slower internet
            if country in ['IN', 'BD', 'PK']:  # Example countries
                return 'wifi' if connection_speed > 5000 else 'mobile_4g'
                
        except Exception:
            pass
        
        # Default for desktop/unknown
        if connection_speed and connection_speed > 20000:  # > 20Mbps
            return 'fiber'
        else:
            return 'wifi'
    
    def select_cdn_endpoint(self, client_ip):
        """Select geographically closest CDN endpoint"""
        try:
            response = self.geoip_reader.city(client_ip)
            continent = response.continent.code
            
            cdn_mapping = {
                'NA': 'us-east-1.cdn.example.com',    # North America
                'EU': 'eu-west-1.cdn.example.com',    # Europe
                'AS': 'ap-southeast-1.cdn.example.com', # Asia
                'SA': 'sa-east-1.cdn.example.com',    # South America
                'OC': 'ap-southeast-2.cdn.example.com', # Oceania
                'AF': 'eu-west-1.cdn.example.com',    # Africa -> EU edge
            }
            
            return cdn_mapping.get(continent, 'global.cdn.example.com')
            
        except Exception:
            return 'global.cdn.example.com'
    
    def generate_manifest(self, video_id, quality_profile, cdn_endpoint):
        """Generate HLS or DASH manifest for adaptive streaming"""
        manifest = {
            'version': '1.0',
            'video_id': video_id,
            'base_url': f'https://{cdn_endpoint}/videos/{video_id}/',
            'streams': [
                {
                    'quality': '240p',
                    'bitrate': 200,
                    'url': f'240p/playlist.m3u8'
                },
                {
                    'quality': '360p', 
                    'bitrate': 500,
                    'url': f'360p/playlist.m3u8'
                },
                {
                    'quality': '720p',
                    'bitrate': 1200,
                    'url': f'720p/playlist.m3u8'
                }
            ],
            'default_quality': quality_profile['resolution']
        }
        
        # Add higher qualities if network supports it
        if quality_profile['bitrate'] >= 2500:
            manifest['streams'].append({
                'quality': '1080p',
                'bitrate': 2500,
                'url': f'1080p/playlist.m3u8'
            })
        
        if quality_profile['bitrate'] >= 8000:
            manifest['streams'].append({
                'quality': '4k',
                'bitrate': 8000,
                'url': f'4k/playlist.m3u8'
            })
        
        return manifest
```

### Key Takeaways:

1. **Design for failure**: Networks will fail, plan for it
2. **Measure latency**: Every remote call has cost
3. **Optimize bandwidth**: Compress, paginate, cache
4. **Secure by default**: Encrypt everything, authenticate all requests  
5. **Embrace change**: Use service discovery, avoid hard-coding
6. **Distributed administration**: Multiple teams, RBAC, proper secrets management
7. **Optimize transport**: Choose efficient protocols và data formats
8. **Adapt to heterogeneity**: Different networks need different approaches

\---

## 64. Request/Reply vs Pub/Sub?

**Trả lời:** Request/Reply và Publish/Subscribe là hai fundamental communication patterns trong distributed systems, mỗi pattern phù hợp cho different use cases và có distinct characteristics.

### Request/Reply Pattern:

#### Characteristics:
- **Synchronous communication**: Caller waits for response
- **Point-to-point**: Direct communication giữa sender và receiver
- **Blocking**: Sender blocked until response received
- **Immediate feedback**: Know immediately if operation succeeded/failed

#### Implementation Example:
```python
# HTTP Request/Reply
import requests
import asyncio
import aiohttp

class UserServiceClient:
    def __init__(self, base_url):
        self.base_url = base_url
    
    # Synchronous Request/Reply
    def get_user_sync(self, user_id):
        response = requests.get(f"{self.base_url}/users/{user_id}")
        
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            raise UserNotFoundError(f"User {user_id} not found")
        else:
            raise ServiceError(f"Service error: {response.status_code}")
    
    # Asynchronous Request/Reply
    async def get_user_async(self, user_id):
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{self.base_url}/users/{user_id}") as response:
                if response.status == 200:
                    return await response.json()
                elif response.status == 404:
                    raise UserNotFoundError(f"User {user_id} not found")
                else:
                    raise ServiceError(f"Service error: {response.status}")

# gRPC Request/Reply
import grpc
import user_service_pb2
import user_service_pb2_grpc

class GRPCUserClient:
    def __init__(self, server_address):
        self.channel = grpc.insecure_channel(server_address)
        self.stub = user_service_pb2_grpc.UserServiceStub(self.channel)
    
    def get_user(self, user_id):
        request = user_service_pb2.GetUserRequest(user_id=user_id)
        
        try:
            response = self.stub.GetUser(request, timeout=10)
            return {
                'id': response.id,
                'name': response.name,
                'email': response.email
            }
        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.NOT_FOUND:
                raise UserNotFoundError(f"User {user_id} not found")
            else:
                raise ServiceError(f"gRPC error: {e.details()}")
    
    def close(self):
        self.channel.close()

# Database Request/Reply
class UserRepository:
    def __init__(self, connection_pool):
        self.pool = connection_pool
    
    async def get_user(self, user_id):
        async with self.pool.acquire() as connection:
            # Request/Reply with database
            result = await connection.fetchrow(
                "SELECT id, name, email FROM users WHERE id = $1", 
                user_id
            )
            
            if result:
                return dict(result)
            else:
                raise UserNotFoundError(f"User {user_id} not found")
```

### Publish/Subscribe Pattern:

#### Characteristics:
- **Asynchronous communication**: Publishers don't wait for subscribers
- **One-to-many**: Single message can reach multiple subscribers
- **Decoupled**: Publishers và subscribers don't know about each other
- **Event-driven**: Based on events/messages rather than direct calls

#### Implementation Examples:
```java
// Redis Pub/Sub
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPubSub;

public class OrderEventPublisher {
    private final Jedis jedis;
    
    public OrderEventPublisher(String redisHost, int redisPort) {
        this.jedis = new Jedis(redisHost, redisPort);
    }
    
    public void publishOrderCreated(Order order) {
        OrderCreatedEvent event = new OrderCreatedEvent(
            order.getId(),
            order.getCustomerId(),
            order.getTotalAmount(),
            System.currentTimeMillis()
        );
        
        String eventJson = gson.toJson(event);
        
        // Publish to multiple channels
        jedis.publish("order.created", eventJson);
        jedis.publish("order.events", eventJson);
        jedis.publish("customer." + order.getCustomerId() + ".orders", eventJson);
    }
    
    public void publishOrderStatusChanged(String orderId, OrderStatus oldStatus, OrderStatus newStatus) {
        OrderStatusChangedEvent event = new OrderStatusChangedEvent(
            orderId, oldStatus, newStatus, System.currentTimeMillis()
        );
        
        String eventJson = gson.toJson(event);
        jedis.publish("order.status-changed", eventJson);
    }
}

public class OrderEventSubscriber extends JedisPubSub {
    @Override
    public void onMessage(String channel, String message) {
        try {
            switch (channel) {
                case "order.created":
                    handleOrderCreated(message);
                    break;
                case "order.status-changed":
                    handleOrderStatusChanged(message);
                    break;
                default:
                    logger.warn("Unknown channel: " + channel);
            }
        } catch (Exception e) {
            logger.error("Error processing message from channel " + channel, e);
        }
    }
    
    private void handleOrderCreated(String message) {
        OrderCreatedEvent event = gson.fromJson(message, OrderCreatedEvent.class);
        
        // Multiple subscribers can handle this independently:
        // 1. Inventory service - reserve items
        // 2. Email service - send confirmation
        // 3. Analytics service - track metrics
        // 4. Audit service - log event
        
        logger.info("Processing order created: " + event.getOrderId());
        
        // Process the event
        inventoryService.reserveItems(event.getOrderId());
        emailService.sendOrderConfirmation(event.getCustomerId(), event.getOrderId());
        analyticsService.recordOrderCreated(event);
    }
}

// Usage
public class Application {
    public static void main(String[] args) {
        OrderEventPublisher publisher = new OrderEventPublisher("localhost", 6379);
        
        // Multiple subscribers can listen to same events
        OrderEventSubscriber inventorySubscriber = new OrderEventSubscriber();
        OrderEventSubscriber emailSubscriber = new OrderEventSubscriber();
        OrderEventSubscriber analyticsSubscriber = new OrderEventSubscriber();
        
        // Each subscriber runs in separate thread
        new Thread(() -> {
            Jedis subscriberJedis = new Jedis("localhost", 6379);
            subscriberJedis.subscribe(inventorySubscriber, "order.created", "order.status-changed");
        }).start();
        
        // Publish events
        Order order = new Order("12345", "customer-1", 99.99);
        publisher.publishOrderCreated(order);
    }
}
```

```python
# Apache Kafka Pub/Sub
from kafka import KafkaProducer, KafkaConsumer
import json
import threading
from typing import Dict, Any

class KafkaEventPublisher:
    def __init__(self, bootstrap_servers=['localhost:9092']):
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            key_serializer=lambda k: str(k).encode('utf-8') if k else None,
            acks='all',  # Wait for all replicas to acknowledge
            retries=3,
            retry_backoff_ms=1000
        )
    
    def publish_user_registered(self, user_data: Dict[str, Any]):
        event = {
            'event_type': 'user_registered',
            'user_id': user_data['user_id'],
            'email': user_data['email'],
            'name': user_data['name'],
            'timestamp': int(time.time() * 1000),
            'version': '1.0'
        }
        
        # Publish to user events topic
        self.producer.send(
            'user.events',
            value=event,
            key=user_data['user_id']  # Partition by user_id for ordering
        )
        
        # Also publish to specific event type topic
        self.producer.send(
            'user.registered',
            value=event,
            key=user_data['user_id']
        )
        
        # Ensure message is sent
        self.producer.flush()
    
    def publish_order_event(self, order_id: str, event_type: str, data: Dict[str, Any]):
        event = {
            'event_type': event_type,
            'order_id': order_id,
            'timestamp': int(time.time() * 1000),
            'data': data
        }
        
        self.producer.send(
            'order.events',
            value=event,
            key=order_id
        )
        self.producer.flush()

class KafkaEventConsumer:
    def __init__(self, topics, group_id, bootstrap_servers=['localhost:9092']):
        self.consumer = KafkaConsumer(
            *topics,
            group_id=group_id,
            bootstrap_servers=bootstrap_servers,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',  # Start from beginning if no offset
            enable_auto_commit=False,  # Manual commit for better control
            consumer_timeout_ms=1000
        )
        self.handlers = {}
    
    def register_handler(self, event_type: str, handler_func):
        """Register handler for specific event type"""
        self.handlers[event_type] = handler_func
    
    def start_consuming(self):
        """Start consuming messages"""
        for message in self.consumer:
            try:
                event = message.value
                event_type = event.get('event_type')
                
                if event_type in self.handlers:
                    # Process event
                    self.handlers[event_type](event)
                    
                    # Commit offset after successful processing
                    self.consumer.commit()
                else:
                    logger.warning(f"No handler for event type: {event_type}")
                    self.consumer.commit()  # Skip unknown events
                    
            except Exception as e:
                logger.error(f"Error processing message: {e}")
                # Don't commit - message will be reprocessed

# Service implementations
class EmailService:
    def __init__(self):
        self.consumer = KafkaEventConsumer(
            ['user.registered', 'order.events'],
            group_id='email-service'
        )
        
        # Register event handlers
        self.consumer.register_handler('user_registered', self.send_welcome_email)
        self.consumer.register_handler('order_created', self.send_order_confirmation)
    
    def send_welcome_email(self, event):
        user_id = event['user_id']
        email = event['email']
        name = event['name']
        
        logger.info(f"Sending welcome email to {email}")
        
        # Send email logic here
        email_content = f"Welcome {name}! Your account has been created."
        self.email_client.send_email(email, "Welcome!", email_content)
    
    def send_order_confirmation(self, event):
        order_id = event['order_id']
        customer_email = event['data']['customer_email']
        
        logger.info(f"Sending order confirmation for order {order_id}")
        
        # Send order confirmation email
        self.email_client.send_email(
            customer_email, 
            "Order Confirmation", 
            f"Your order {order_id} has been confirmed."
        )
    
    def start(self):
        # Start consuming in separate thread
        consumer_thread = threading.Thread(target=self.consumer.start_consuming)
        consumer_thread.daemon = True
        consumer_thread.start()

class InventoryService:
    def __init__(self):
        self.consumer = KafkaEventConsumer(
            ['order.events'],
            group_id='inventory-service'
        )
        self.consumer.register_handler('order_created', self.reserve_inventory)
        self.consumer.register_handler('order_cancelled', self.release_inventory)
    
    def reserve_inventory(self, event):
        order_id = event['order_id']
        items = event['data']['items']
        
        logger.info(f"Reserving inventory for order {order_id}")
        
        for item in items:
            product_id = item['product_id']
            quantity = item['quantity']
            
            if self.check_stock(product_id, quantity):
                self.reserve_stock(product_id, quantity)
            else:
                # Publish inventory unavailable event
                publisher.publish_order_event(
                    order_id, 
                    'inventory_unavailable',
                    {'product_id': product_id, 'requested_quantity': quantity}
                )
```

### Comparison Table:

| Aspect | Request/Reply | Pub/Sub |
|--------|---------------|---------|
| **Communication** | Synchronous | Asynchronous |
| **Coupling** | Tight coupling | Loose coupling |
| **Response** | Immediate | No direct response |
| **Scalability** | Limited by bottlenecks | Highly scalable |
| **Reliability** | Immediate error feedback | At-least-once delivery |
| **Use Cases** | CRUD operations, queries | Events, notifications |

### When to Use Request/Reply:

#### 1. CRUD Operations:
```javascript
// Perfect for database operations
const userService = {
    async createUser(userData) {
        // Need immediate feedback about success/failure
        const result = await database.users.create(userData);
        
        if (result.error) {
            throw new ValidationError(result.error.message);
        }
        
        return result.user;
    },
    
    async getUser(userId) {
        // Caller needs the data immediately
        const user = await database.users.findById(userId);
        
        if (!user) {
            throw new NotFoundError(`User ${userId} not found`);
        }
        
        return user;
    }
};
```

#### 2. Real-time Queries:
```python
# Search and filtering - need immediate results
class SearchService:
    def search_products(self, query, filters):
        # User is waiting for search results
        results = self.elasticsearch.search(
            index='products',
            body={
                'query': {
                    'bool': {
                        'must': [
                            {'match': {'name': query}},
                            {'terms': {'category': filters.get('categories', [])}}
                        ]
                    }
                }
            }
        )
        
        return {
            'products': results['hits']['hits'],
            'total': results['hits']['total']['value'],
            'took': results['took']
        }
```

#### 3. Transaction Processing:
```java
// Payment processing - need immediate confirmation
@Service
public class PaymentService {
    
    public PaymentResult processPayment(PaymentRequest request) {
        // Critical operation requiring immediate feedback
        
        try {
            // Validate payment details
            validatePaymentDetails(request);
            
            // Charge payment gateway
            ChargeResponse response = paymentGateway.charge(
                request.getAmount(),
                request.getPaymentMethod()
            );
            
            if (response.isSuccessful()) {
                // Update order status immediately
                orderService.markAsPaid(request.getOrderId());
                
                return PaymentResult.success(
                    response.getTransactionId(),
                    request.getAmount()
                );
            } else {
                return PaymentResult.failure(response.getErrorMessage());
            }
            
        } catch (Exception e) {
            return PaymentResult.failure("Payment processing failed: " + e.getMessage());
        }
    }
}
```

### When to Use Pub/Sub:

#### 1. Event-Driven Architecture:
```python
# Multiple services need to react to events
class OrderEventSystem:
    def __init__(self, event_publisher):
        self.publisher = event_publisher
    
    def create_order(self, order_data):
        # Create order first
        order = self.order_repository.create(order_data)
        
        # Publish event - multiple services will react
        self.publisher.publish('order.created', {
            'order_id': order.id,
            'customer_id': order.customer_id,
            'items': order.items,
            'total_amount': order.total_amount
        })
        
        return order

# Multiple independent subscribers
class InventorySubscriber:
    def handle_order_created(self, event):
        # Reserve inventory
        self.reserve_items(event['items'])

class EmailSubscriber:
    def handle_order_created(self, event):
        # Send confirmation email
        self.send_order_confirmation(event['customer_id'], event['order_id'])

class AnalyticsSubscriber:
    def handle_order_created(self, event):
        # Track metrics
        self.record_sale(event['total_amount'])
        self.update_customer_stats(event['customer_id'])
```

#### 2. Microservices Integration:
```go
// Loosely coupled microservices communication
type UserService struct {
    eventPublisher EventPublisher
}

func (us *UserService) RegisterUser(userData UserRegistrationData) (*User, error) {
    // Create user
    user, err := us.userRepository.Create(userData)
    if err != nil {
        return nil, err
    }
    
    // Publish event - other services will react independently
    event := UserRegisteredEvent{
        UserID:    user.ID,
        Email:     user.Email,
        Name:      user.Name,
        Timestamp: time.Now(),
    }
    
    us.eventPublisher.Publish("user.registered", event)
    
    return user, nil
}

// Independent services can subscribe
type WelcomeEmailService struct{}

func (w *WelcomeEmailService) HandleUserRegistered(event UserRegisteredEvent) {
    // Send welcome email
    w.emailSender.SendWelcomeEmail(event.Email, event.Name)
}

type LoyaltyProgramService struct{}

func (l *LoyaltyProgramService) HandleUserRegistered(event UserRegisteredEvent) {
    // Create loyalty account
    l.loyaltyRepository.CreateAccount(event.UserID)
}
```

#### 3. Fan-out Processing:
```python
# Single event triggers multiple processing workflows
class MediaProcessingService:
    def upload_video(self, video_file, metadata):
        # Store original video
        video_id = self.video_storage.store(video_file)
        
        # Publish event - multiple processors will handle different tasks
        self.publisher.publish('video.uploaded', {
            'video_id': video_id,
            'file_size': video_file.size,
            'duration': metadata.get('duration'),
            'format': metadata.get('format')
        })
        
        return video_id

# Multiple processors handle different aspects
class ThumbnailProcessor:
    def handle_video_uploaded(self, event):
        # Generate thumbnails
        self.generate_thumbnails(event['video_id'])

class TranscodingProcessor:
    def handle_video_uploaded(self, event):
        # Transcode to different formats
        self.transcode_video(event['video_id'])

class MetadataProcessor:
    def handle_video_uploaded(self, event):
        # Extract metadata
        self.extract_metadata(event['video_id'])

class ContentModerationProcessor:
    def handle_video_uploaded(self, event):
        # Check for inappropriate content
        self.moderate_content(event['video_id'])
```

### Hybrid Approaches:

#### Request/Reply with Async Follow-up:
```javascript
// Immediate response + background processing
class OrderService {
    async createOrder(orderData) {
        // Immediate processing
        const order = await this.orderRepository.create(orderData);
        
        // Publish for background processing
        await this.eventPublisher.publish('order.created', {
            orderId: order.id,
            customerId: order.customerId,
            items: order.items
        });
        
        // Return immediate response
        return {
            orderId: order.id,
            status: 'created',
            estimatedDelivery: this.calculateDeliveryDate()
        };
    }
}
```

### Key Decision Factors:

1. **Need immediate response?** → Request/Reply
2. **Multiple consumers for same event?** → Pub/Sub  
3. **Critical operation that must succeed?** → Request/Reply
4. **Loose coupling preferred?** → Pub/Sub
5. **High scalability required?** → Pub/Sub
6. **Simple point-to-point communication?** → Request/Reply

---

*Post ID: v24x8r71w74t2oo*  
*Category: BackEnd Interview*  
*Created: 2/9/2025*  
*Updated: 2/9/2025*
